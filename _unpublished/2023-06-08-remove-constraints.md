---
title: Remove Constraints Instead Of Saying What Good Look Like
---

We look at the world and take decision for our actions through models. Depending
on the context, some model will be more fruitful to apply than others. There is
a model that I have found tremendously useful, in particular when discussion
"open source supply chain" but also more regularly as a SRE. I dub this model
"Goals/Capability/Constraints". It tends to evaluate action far differently than
most of the other model I have seen applied to these domains. The main
recommendation it nearly always give is to "remove constraints".

While this is sometimes hard to do, it has the advantage of being particularly
emphatic to the needs of the people that actually do the work. It also has the
inconvenient to mostly point out that your great ideas are not going to help.
This means that it tends to be neglected, as it is far easier to feel right but
be wrong than accept we were wrong.

## All Models Are Wrong

If you listen to the thought leadership around safety, infosec or even
management, you tend to get offered two levers of actions. Changing the
Incentives, making some actions more or less rewarded, and adding regulations or
control, which translate to punishing people and organizations that do the thing
you do not want to do. If you are lucky, you will be offered a third option to
"show what good look like", also known as "aligning on objectives".

Equipped with your trio of tools, you can now modify complex social systems in
order to achieve your goal of making "bad" outcomes happen far less. It is a
particularly useful trifecta of tools if you think that the humans in your
systems are taking bad decisions. After all, if they take bad decisions, all you
need is reward the good decisions, punish the bad decisions and make sure
everyone know what is good and bad. Easy peasy, we can wrap that one up and be
home before tea time.

In this model, decision making is basically a "spherical cow". If we have a
human having to take a decisions, they float freely in the space of all the
possible choice they can make. And they will pick the most rewarded path,
avoiding the punished one, while trying to do the "right thing", which we
explained to them.

Well, the problem of course is that despite doing this all the time, people keep
taking bad decisions. They keep shipping insecure software. Using all the
dependencies. Not vetting all their software dependencies. The FOSS maintainers
keep refusing to cryptographically sign all their commits. They keep not doing
crypto right. They keep refusing to use memory safe languages. Really, it seems
that despite us trying to be really nice, explaining it all, and also punishing
them if they do the wrong thing ... they keep stubornly doing the "wrong thing".
Maybe they are just impossible to fix. Maybe it is time to bring the regulators.
Let's double down and up the ante. Or maybe... maybe it is just not right?

If a model fail to deliver, it may be because it is not adapted to the problem
at hand. That is not to say it is never right or useful, but maybe right now it
does not apply really well. I think the "Incentives/Punishement/Goals" model is
definitely in that situation here. Despite all our tentative to apply it, we
keep getting the system and results from before it. That is usually a telltale
of using the wrong model.

## Some Models Are Useful

The "Goals/Capabilities/Constraints" is slightly different. It is still a model
that analyse how people make decisions. It starts with where the decision maker
is today, in the present. Then we look at what Goals we want to achieve. This
represent where we want to be in the future. Once we know where we are now, and
where we want to be then, in the future, we move to how to get there.

Capabilities are the tools, knowledge, skillset and ressources we have access
to. These define the possible paths toward our goals. Their combinations,
through time, give us all the different branching trees of possible path from
here and now to there in the future. These paths start now, and every choice we
will make branch off, until at some point we reach the Goals we want. That makes
a lot of branch, so let see how we make a choice, by pruning some of them.

Constraints are all the things that limit our choices. This is the realm of
ethics, regulations, laws, punishments, cultural norms, but also time
constraints, ressources limitations, burn out, bankruptcy or budgets. Anything
that could make us choose to not take a path we are _capable_ of taking but
cannot accept to take. Constraints are applied to the tree of path generated by
Capabilities to reach Goals, and prune these paths. The end result offer a far
smaller set of paths.

Where the previous model considered that you have to push and prod the decision
maker, this model consider that the decision maker choices are defined by what
they have available and are then refined through the limitations they have to
deal with. This is a model built on frustration.

## When There Are No Way Out

But the frustration get worse. Because it can happen that the set of constraints
is so large and imposing that after pruning by Constraints ... there are no path
left toward the Goals with our Capabilities. The Constraints are too numeroux
and too strict, while our Capabilities are too limited, to reach our Goal. Well,
that is frustrating.

Things get worse. See, as far as research on Safety tell us, this set of no path
forward due to over constraints is pretty universally the default state for
workers. Every day normal work in these situations, which are ubiquituous, means
having no acceptable path forward. So what do you do when you end up in this
situation? Well, it is simple right? You break the rules! You usually do not
constrol all the goals (after all if you are employed, you do not set them), and
your capabilities are usually relatively static.

When everything else is fixed, it seems the only thing that can change is
constraints. That is what we means by tradeoff. If we want workers to reach this
goals with the tools and ressources they have, well they will have to not
respect some of the constraints. Vetting all 3rd party dependencies? Yeah no.
Signing my commits? Noone cares, not an important constraint. Working code? That
one I cannot ignore, otherwise we cannot reach the goal. Having CI? Non
essential. A reproducible build? Let's try to be able to build it all first Jan,
and then maybe one day sure.

This is the reality of working at the "sharp edge". This is where every action
is a balancing act, trying to stay at the edge of what is acceptable, breaking
the rules just in the ways that will be enough to achieve goals without getting
too much into the unstability that wait for you if you go too far into trading
off constratins for results.

## Changing Things For The Better

So, if we use this model to explain our systems work today, how can we use it to
try to change how they will work tomorrow. We will take for granted that right
now, at best, the combination of Capabilities and Constraints gives us or no
path toward our Goals, or a really narrow path. If we take this for granted,
then we have four different levers. We could convince people to want a different
goal. Low chance of impact in outcome though, because the constratins will
probably limit the paths as much. We could provide new Capabilities, but that is
usually complicated or too expensive to consider. We could add more Constraints,
like adding regulations, but if the problem is already over constrained, adding
more will have no effects, other than forcing the workers to break more of the
Constratins just to get things done.

Or we could remove some constraints. This may not open the possible paths this
much, but at the very least it would open space for different tradeoffs. After
the constraints are removed or lossened, we can trade off the newly opened space
to find a new path fowrward, that may break less of the Constraints we had.

As an example, if we have heavy ressources constraints, like a couple hours of
work per week, then any project that need sustained attention and memory for
dozens of hours is not possible. Dozens of hours would take us a dozen of weeks
to reach. By that point, it is doubtful that we would have maintained sustained
attention for that long time, with a lot of interuptions and unrelated work in
between. We are pretty far from Flow-State. As such, this path will never be
considered. If this is the only one possible to get rid of a legacy, unsafe,
behaviour in our software, we will simply mark the behaviour as deprecated but
never do the work to actually get rid of it. Not because we do not want to get
rid of it, or that we do not prioritize it. But simply because we _cannot do
it_. We are too constrained. So we traded off the security constraints.[^1]

We could attack the constraint on two aspects. First we could find a way to work
multiple hours per day on this project. This would reduce the duration of the
implementation to a few days, which would allows deep attention and memory. We
could also introduce new tools and techniques, which would allows to reduce the
duration of the attention needed. Intermediate states. Tools and languages that
would support doing the work faster. Anything that can reduce the constraints
imposed on the worker would change the trade offs. And at some point, if we
reduce the constraints enough, then the worker can actually get rid of the
unsafe behaviour.

## If You Are Not Reducing Constraints, Stop And Reevaluate

So what have we learned? That a model of Goals/Capabilities/Constraints can
explain how workers take decisions that may seem "wrong" from the outside. In
this case, the model tell us that the situation had so many constraints that the
worker had to trade off some of the goals and constraints in order to achieve a
partial success. If we want workers in these kind of situation to achieve "good"
outcomes, we have four levers.

1. Change goals, which is usually hard to achieve and necessitate a lot of persuasion
2. Provide new Capabilities, which is usually complicated as it means training people
3. Add new Constraints, which will be traded off, as there was already no
   succesful path to a "good" outcome. Reducing the options hardly helps.
4. Remove Constraints, allowing path to "good" outcomes to become possible, and
   as such used.

We can classify all actions we would take to influence the outcome "for the
better" under these four categories. I will let to the reader the exercice to
map their organisation action plan to reduce "bad" outcomes into these
categories. If you do it, I would be interested to know how the distribution of
actions into categories look like for you. I can give you a bet though. I bet
the fourth category is nearly empty for all of my readers.

We seldom offer actions that remove Constraints. And yet, this is the most
impactful, if not the only impactful, of the category of actions we described
today, based on this Goals/Capabilities/Constraints model. So here is my plea.
If you imagine an action to make the system better. Please try to see which of
the four category it correspond to. And if it is not a fourth category action,
consider not doing it. Why not try to spend all your energy and time into doing
the most effective and impactful actions? Remove Constraints instead.

---------

[^1]: Any similarity to actual events, particularly to certain java libraries,
    are allegedly fortuitous.
