---
title: Remove Constraints Instead Of Saying What Good Look Like
---

We look at the world and take decision for our actions through models. Depending
on the context, some model will be more fruitful to apply than others. There is
a model that I have found tremendously useful, in particular when discussion
"open source supply chain" but also more regularly as a SRE. I dub this model
"Goals/Capability/Constraints". It tends to evaluate action far differently than
most of the other model I have seen applied to these domains. The main
recommendation it nearly always give is to "remove constraints".

While this is sometimes hard to do, it has the advantage of being particularly
emphatic to the needs of the people that actually do the work. It also has the
inconvenient to mostly point out that your great ideas are not going to help.
This means that it tends to be neglected, as it is far easier to feel right but
be wrong than accept we were wrong.

## All Models Are Wrong

If you listen to the thought leadership around safety, infosec or even
management, you tend to get offered two levers of actions. Changing the
Incentives, making some actions more or less rewarded, and adding regulations or
control, which translate to punishing people and organizations that do the thing
you do not want to do. If you are lucky, you will be offered a third option to
"show what good look like", also known as "aligning on objectives".

Equipped with your trio of tools, you can now modify complex social systems in
order to achieve your goal of making "bad" outcomes happen far less. It is a
particularly useful trifecta of tools if you think that the humans in your
systems are taking bad decisions. After all, if they take bad decisions, all you
need is reward the good decisions, punish the bad decisions and make sure
everyone know what is good and bad. Easy peasy, we can wrap that one up and be
home before tea time.

In this model, decision making is basically a "spherical cow". If we have a
human having to take a decisions, they float freely in the space of all the
possible choice they can make. And they will pick the most rewarded path,
avoiding the punished one, while trying to do the "right thing", which we
explained to them.

Well, the problem of course is that despite doing this all the time, people keep
taking bad decisions. They keep shipping insecure software. Using all the
dependencies. Not vetting all their software dependencies. The FOSS maintainers
keep refusing to cryptographically sign all their commits. They keep not doing
crypto right. They keep refusing to use memory safe languages. Really, it seems
that despite us trying to be really nice, explaining it all, and also punishing
them if they do the wrong thing ... they keep stubornly doing the "wrong thing".
Maybe they are just impossible to fix. Maybe it is time to bring the regulators.
Let's double down and up the ante. Or maybe... maybe it is just not right?

If a model fail to deliver, it may be because it is not adapted to the problem
at hand. That is not to say it is never right or useful, but maybe right now it
does not apply really well. I think the "Incentives/Punishement/Goals" model is
definitely in that situation here. Despite all our tentative to apply it, we
keep getting the system and results from before it. That is usually a telltale
of using the wrong model.

## Some Models Are Useful

The "Goals/Capabilities/Constraints" is slightly different. It is still a model
that analyse how people make decisions. It starts with where the decision maker
is today, in the present. Then we look at what Goals we want to achieve. This
represent where we want to be in the future. Once we know where we are now, and
where we want to be then, in the future, we move to how to get there.

Capabilities are the tools, knowledge, skillset and ressources we have access
to. These define the possible paths toward our goals. Their combinations,
through time, give us all the different branching trees of possible path from
here and now to there in the future. These paths start now, and every choice we
will make branch off, until at some point we reach the Goals we want. That makes
a lot of branch, so let see how we make a choice, by pruning some of them.

Constraints are all the things that limit our choices. This is the realm of
ethics, regulations, laws, punishments, cultural norms, but also time
constraints, ressources limitations, burn out, bankruptcy or budgets. Anything
that could make us choose to not take a path we are _capable_ of taking but
cannot accept to take. Constraints are applied to the tree of path generated by
Capabilities to reach Goals, and prune these paths. The end result offer a far
smaller set of paths.

Where the previous model considered that you have to push and prod the decision
maker, this model consider that the decision maker choices are defined by what
they have available and are then refined through the limitations they have to
deal with. This is a model built on frustration.

## When There Are No Way Out

But the frustration get worse. Because it can happen that the set of constraints
is so large and imposing that after pruning by Constraints ... there are no path
left toward the Goals with our Capabilities. The Constraints are too numeroux
and too strict, while our Capabilities are too limited, to reach our Goal. Well,
that is frustrating.

Things get worse. See, as far as research on Safety tell us, this set of no path
forward due to over constraints is pretty universally the default state for
workers. Every day normal work in these situations, which are ubiquituous, means
having no acceptable path forward. So what do you do when you end up in this
situation? Well, it is simple right? You break the rules! You usually do not
constrol all the goals (after all if you are employed, you do not set them), and
your capabilities are usually relatively static.

When everything else is fixed, it seems the only thing that can change is
constraints. That is what we means by tradeoff. If we want workers to reach this
goals with the tools and ressources they have, well they will have to not
respect some of the constraints. Vetting all 3rd party dependencies? Yeah no.
Signing my commits? Noone cares, not an important constraint. Working code? That
one I cannot ignore, otherwise we cannot reach the goal. Having CI? Non
essential. A reproducible build? Let's try to be able to build it all first Jan,
and then maybe one day sure.

This is the reality of working at the "sharp edge". This is where every action
is a balancing act, trying to stay at the edge of what is acceptable, breaking
the rules just in the ways that will be enough to achieve goals without getting
too much into the unstability that wait for you if you go too far into trading
off constratins for results.

## Changing Things For The Better

So, if we use this model to explain our systems work today, how can we use it to
try to change how they will work tomorrow. We will take for granted that right
now, at best, the combination of Capabilities and Constraints gives us or no
path toward our Goals, or a really narrow path. If we take this for granted,
then we have four different levers. We could convince people to want a different
goal. Low chance of impact in outcome though, because the constratins will
probably limit the paths as much. We could provide new Capabilities, but that is
usually complicated or too expensive to consider. We could add more Constraints,
like adding regulations, but if the problem is already over constrained, adding
more will have no effects, other than forcing the workers to break more of the
Constratins just to get things done.

Or we could remove some constraints. This may not open the possible paths this
much, but at the very least it would open space for different tradeoffs. As now,
we can trade off the newly eliminated constraint space to find a new path
fowrward, that may break less of the Constraints we had.
